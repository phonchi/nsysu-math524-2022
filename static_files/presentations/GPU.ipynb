{"cells":[{"cell_type":"markdown","metadata":{"id":"2OwsMW68aOLV"},"source":["## Enhancing performance using GPGPU\n","In the 90s and 2000s, graphics hardware was designed to cater to specific needs, especially for workloads in the graphics industry. But graphics workloads demanded increasing computing power. Graphics hardware was increasing performance at more than 2.4 times per year, faster than Moore’s law predicted. NVIDIA graphics processing units (GPUs) were originally designed for running games and graphics workloads that were highly parallel in nature. Because of high demand for FLOPS and memory bandwidth in the gaming and graphics industry, GPUs evolved into a highly parallel, multithreaded, manycore processor with enormous computational horsepower and high memory bandwidth. This started the era of GPGPU:  general purpose computing on GPUs that were originally designed to accelerate only specific workloads like gaming and graphics. "]},{"cell_type":"markdown","metadata":{"id":"E_rreUVmaOLb"},"source":["<center><img src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2020/04/GPU-transistor-625x314.png\"></center>\n","<center><img src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2021/guc/oNUz_VDLm8Gzzhuecn7dT15DSUSDfox0q75vX1NqR3vaUl8zm8GW4xddDgQ9Oe87SZt8H4A2ZVrgQRWN5SFgTTxEqG-0JL7STZvGNfwLSGvv3NMPYaPl5qUjAQDkPVr7oovlQsGO.png\"></center>\n","\n","\n","<div align=\"center\"> source: https://developer.nvidia.com/blog/cuda-refresher-reviewing-the-origins-of-gpu-computing/ </div>"]},{"cell_type":"markdown","metadata":{"id":"GVaLpdxhaOLb"},"source":["GPUs dedicate most of their transistors for data processing while CPUs also need to reserve die area for big caches, control units, and so on. CPU processors work on the principle of minimizing latency within each thread while GPUs hide the instruction and memory latencies with computation. Figure 3 shows the difference in computation threads. "]},{"cell_type":"markdown","metadata":{"id":"mx0DN0V_aOLb"},"source":["## Using `Numba`\n","`Numba` supports CUDA GPU programming by directly compiling a restricted subset of Python code into CUDA kernels and device functions following the CUDA execution model. Kernels written in Numba appear to have direct access to NumPy arrays. NumPy arrays are transferred between the CPU and the GPU automatically."]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"id":"G42TDVPkbdY2"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EsOsyOtSaOLc"},"outputs":[],"source":["#import os\n","#os.environ['NUMBA_ENABLE_CUDASIM'] = '1'\n","from numba import cuda\n","import numba as nb\n","import numpy as np\n","import math"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Ff7o9IZaOLc"},"outputs":[],"source":["print(cuda.gpus)"]},{"cell_type":"markdown","metadata":{"id":"cGiBcs_EaOLd"},"source":["If your machine has multiple GPUs, you might want to select which one to use"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_bVNNrKUaOLd"},"outputs":[],"source":["nb.cuda.select_device(0)"]},{"cell_type":"markdown","metadata":{"id":"ZvlroQUxaOLd"},"source":["Using the CUDA simulator\n","\n","If you don’t have a CUDA-enabled GPU (i.e. you received one of the error messages described previously), then you will need to use the CUDA simulator. The simulator is enabled by setting the environment variable NUMBA_ENABLE_CUDASIM to 1.\n","\n","- Mac/Linux: Launch a terminal shell and type the commands:\n","`export NUMBA_ENABLE_CUDASIM=1`\n","\n","- Windows: Launch a CMD shell and type the commands:\n","`SET NUMBA_ENABLE_CUDASIM=1`"]},{"cell_type":"markdown","metadata":{"id":"9PuOntuWaOLd"},"source":["### Kernel\n","CUDA kernel is a function that gets executed on GPU. The parallel portion of your applications is executed K times in parallel by K different CUDA threads.\n","CUDA defines built-in 3D variables for threads and blocks.Three-dimensional indexing provides a natural way to index elements in vectors, matrix, and volume and makes CUDA programming easier\n","\n","- kernels cannot explicitly return a value; all result data must be written to an array passed to the function (if computing a scalar, you will probably pass a one-element array);\n","- kernels explicitly declare their thread hierarchy when called: i.e. the number of thread blocks and the number of threads per block (note that while a kernel is compiled once, it can be called multiple times with different block sizes or grid sizes)."]},{"cell_type":"markdown","metadata":{"id":"1fineT3uaOLe"},"source":["<center><img src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2020/06/kernel-execution-on-gpu-1-625x438.png\"></center>\n","\n","<div align=\"center\"> source: https://developer.nvidia.com/blog/cuda-refresher-cuda-programming-model/ </div>"]},{"cell_type":"markdown","metadata":{"id":"gPTs9frvaOLe"},"source":["When running, the kernel function’s code is executed by every thread once. It therefore has to know which thread it is in, in order to know which array element(s) it is responsible for. In programming, one way is determines the thread position in the grid and block and manually compute the corresponding array position:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DIf7vJu3aOLe"},"outputs":[],"source":["@cuda.jit\n","def my_kernel(io_array):\n","    # Thread id in a 1D block\n","    tx = cuda.threadIdx.x\n","    # Block id in a 1D grid\n","    ty = cuda.blockIdx.x\n","    # Block width, i.e. number of threads per block\n","    bw = cuda.blockDim.x\n","    # Compute flattened index inside the array\n","    pos = tx + ty * bw\n","    if pos < io_array.size:  # Check array boundaries\n","        io_array[pos] *= 2 # do the computation"]},{"cell_type":"markdown","metadata":{"id":"2-dp6z0jaOLe"},"source":["Numba provides additional facilities to automate such calculations:\n","\n","- `numba.cuda.grid(ndim)` - Return the absolute position of the current thread in the entire grid of blocks. ndim should correspond to the number of dimensions declared when instantiating the kernel. If `ndim` is 1, a single integer is returned. If `ndim` is 2 or 3, a tuple of the given number of integers is returned.\n","- `numba.cuda.gridsize(ndim)` - Return the absolute size (or shape) in threads of the entire grid of blocks. ndim has the same meaning as in `grid()` above."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p0R7dyxLaOLf"},"outputs":[],"source":["@cuda.jit\n","def my_kernel2(io_array):\n","    pos = cuda.grid(1)\n","    if pos < io_array.size:\n","        io_array[pos] *= 2 # do the computation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KrTiXiqKaOLf"},"outputs":[],"source":["# Host code   \n","data = np.ones(256)\n","threadsperblock = 256\n","blockspergrid = math.ceil(data.shape[0] / threadsperblock)\n","my_kernel2[blockspergrid, threadsperblock](data)\n","data"]},{"cell_type":"markdown","metadata":{"id":"cxVPs417aOLf"},"source":["For 2D data the index is similar"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IsHP07vCaOLf"},"outputs":[],"source":["@cuda.jit\n","def my_kernel_2D(io_array):\n","    x, y = cuda.grid(2)\n","    if x < io_array.shape[0] and y < io_array.shape[1]:\n","        io_array[x, y] *= 2 # do the computation\n","        \n","data = np.ones((16, 16))\n","threadsperblock = (16, 16)\n","blockspergrid_x = math.ceil(data.shape[0] / threadsperblock[0])\n","blockspergrid_y = math.ceil(data.shape[1] / threadsperblock[1])\n","blockspergrid = (blockspergrid_x, blockspergrid_y)\n","my_kernel_2D[blockspergrid, threadsperblock](data)\n","data"]},{"cell_type":"markdown","metadata":{"id":"kujOnAivaOLf"},"source":["### Matrix multiplication\n","Each thread reads one row of A and one column of B and computes the corresponding element of C. For input arrays where A.shape == (m, n) and B.shape == (n, p) then the result shape will be C.shape = (m, p)."]},{"cell_type":"markdown","metadata":{"id":"a5CRREwNaOLf"},"source":["<center><img src=\"https://nyu-cds.github.io/python-numba/fig/05-matmul.png\"></center>\n","\n","<div align=\"center\"> source: https://nyu-cds.github.io/python-numba/05-cuda/ </div>"]},{"cell_type":"markdown","metadata":{"id":"cXsCUaDSaOLf"},"source":["There are two main steps:\n","\n","- Instantiate the kernel proper, by specifying a number of blocks per grid and a number of threads per block. The product of the two will give the total number of threads launched. Kernel instantiation is done by taking the compiled kernel function and indexing it with a tuple of integers.\n","- Running the kernel, by passing it the input array (and any separate output arrays if necessary). By default, running a kernel is synchronous: the function returns when the kernel has finished executing and the data is synchronized back.\n","\n","- Data is copied from the CPU (host) to the GPU (device), where it is computed on. After a computation, it need to be copied back to the CPU to be interacted with by numpy, etc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bvoUigB6aOLg"},"outputs":[],"source":["# CUDA kernel\n","@cuda.jit\n","def matmul(A, B, C):\n","    \"\"\"Perform matrix multiplication of C = A * B\n","    \"\"\"\n","    row, col = cuda.grid(2)\n","    if row < C.shape[0] and col < C.shape[1]:\n","        tmp = 0.\n","        for k in range(A.shape[1]):\n","            tmp += A[row, k] * B[k, col]\n","        C[row, col] = tmp"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SIUWamfXaOLg"},"outputs":[],"source":["# Host code\n","\n","# Numba has been automatically transferring the NumPy arrays to the device when you invoke the kernel.\n","# Initialize the data arrays\n","A = np.full((24, 12), 3, np.float) # matrix containing all 3's\n","B = np.full((12, 22), 4, np.float) # matrix containing all 4's\n","C = np.empty((24,22), np.float)\n","\n","# Configure the blocks\n","threadsperblock = (16, 16)\n","blockspergrid_x = int(math.ceil(A.shape[0] / threadsperblock[0]))\n","blockspergrid_y = int(math.ceil(B.shape[1] / threadsperblock[1]))\n","blockspergrid = (blockspergrid_x, blockspergrid_y)\n","\n","# Start the kernel \n","matmul[blockspergrid, threadsperblock](A, B, C)\n","\n","C"]},{"cell_type":"markdown","metadata":{"id":"wqjSGfQkaOLg"},"source":["- Check share memory https://nyu-cds.github.io/python-numba/05-cuda/ and https://numba.pydata.org/numba-doc/dev/cuda/examples.html\n","    "]},{"cell_type":"markdown","metadata":{"id":"vtUslr_3aOLg"},"source":["## Using `CuPy`\n","Simply put: `CuPy` is `NumPy`, but for the GPU. Preferred Networks created CuPy as the GPU backend for their deep learning library, Chainer, but it also works great as a standalone NumPy-like GPU array library. If you know NumPy, CuPy is a very easy way to get started on the GPU.\n","\n","CuPy also includes the following features for performance:\n","\n","- User-defined elementwise CUDA kernels\n","- Includes frequently used functions from `SciPy`. \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yjgu6en2aOLg"},"outputs":[],"source":["from cupy.cuda import nvrtc\n","import cupy as cp\n","nvrtc.getVersion()"]},{"cell_type":"markdown","metadata":{"id":"HvjjYfBvaOLg"},"source":["### RawKernel"]},{"cell_type":"code","source":["!wget https://seeklogo.com/images/N/NVIDIA-logo-BA019CBFAA-seeklogo.com.png -O LOGO.png"],"metadata":{"id":"7b-IHAZcb627"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c0kADE1laOLg"},"outputs":[],"source":["from PIL import Image\n","logo_img = Image.open(\"LOGO.png\") #source: https://seeklogo.com/vector-logo/101614/nvidia\n","\n","from IPython.display import display\n","display(logo_img)"]},{"cell_type":"code","source":["logo_img.split()"],"metadata":{"id":"qdhcXN0dcT1q"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"obTn8fqjaOLh"},"outputs":[],"source":["(r, g, b, a) = logo_img.split()\n","\n","r_array = np.array(r)\n","g_array = np.array(g)\n","b_array = np.array(b)\n","a_array = np.array(a)\n","logo_array = np.stack((r_array, g_array, b_array))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v-elcXt5aOLh"},"outputs":[],"source":["in_gpu_array = cp.array(logo_array)\n","out_gpu_array = cp.empty_like(in_gpu_array)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YoSRkgcLaOLh"},"outputs":[],"source":["img_add_const_value_kernel = cp.RawKernel(r'''\n","    extern \"C\" __global__\n","    void img_add_const_value(unsigned char* dst, unsigned char* src, int w, int h, int v) {\n","        int x = blockIdx.x * blockDim.x + threadIdx.x;\n","        int y = blockIdx.y * blockDim.y + threadIdx.y;\n","        int z = blockIdx.z * blockDim.z + threadIdx.z;\n","        if (x < w && y < h) {\n","            src += w * h * z;\n","            dst += w * h * z;\n","            int pos = y * w + x;\n","            int tmp = (int)src[pos] + v;\n","            tmp = (tmp > 255) ? 255:tmp;\n","            tmp = (tmp <   0) ?   0:tmp;\n","            dst[pos] = tmp;\n","        }\n","    }\n","    ''', 'img_add_const_value')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7ecdORL6aOLh"},"outputs":[],"source":["(c, h, w) = in_gpu_array.shape\n","block = (16, 16, 1)\n","grid = ((w + 15)//16, (h + 15)//16, c)\n","img_add_const_value_kernel(grid, block, (out_gpu_array, in_gpu_array, w, h, 100))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4GSH0_s_aOLh"},"outputs":[],"source":["out_logo_array = cp.asnumpy(out_gpu_array)\n","\n","r_img = Image.fromarray(out_logo_array[0,:,:])\n","g_img = Image.fromarray(out_logo_array[1,:,:])\n","b_img = Image.fromarray(out_logo_array[2,:,:])\n","a_img = Image.fromarray(a_array)\n","out_img = Image.merge('RGBA', (r_img, g_img, b_img, a_img))\n","display(out_img)"]},{"cell_type":"markdown","metadata":{"id":"wCftFuIfaOLh"},"source":["### Array oriented programming"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mNX3QuUNaOLi"},"outputs":[],"source":["cp.cuda.Device(0).use()\n","x_gpu = cp.arange(1000)\n","x_cpu = np.arange(1000)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jnTgDdk8aOLi"},"outputs":[],"source":["np.linalg.norm(x_cpu)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hj2uT02yaOLi"},"outputs":[],"source":["cp.linalg.norm(x_gpu)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1qqdRTsuaOLi"},"outputs":[],"source":["m = 1000\n","n = 1000\n","p = 100\n","\n","X1 = np.random.random((m, p))\n","Y1 = np.random.random((p, n))\n","\n","X2 = cp.random.random((m, p))\n","Y2 = cp.random.random((p, n))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"519UofYHaOLi"},"outputs":[],"source":["%timeit X1.dot(Y1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6-RWWlZXaOLj"},"outputs":[],"source":["%timeit X2.dot(Y2)"]},{"cell_type":"markdown","metadata":{"id":"4NIsHxWbaOLj"},"source":["MonteCarlo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l2K8DCpMaOLj"},"outputs":[],"source":["def monte_carlo_pi(n):\n","    x = np.random.uniform(-1, 1, (n,2))\n","    return 4*np.sum((x**2).sum(1) < 1)/n\n","\n","def monte_carlo_pi_cp(n):\n","    x = cp.random.uniform(-1, 1, (n,2))\n","    return 4*cp.sum((x**2).sum(1) < 1)/n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UaQHeevraOLj"},"outputs":[],"source":["%%timeit\n","[monte_carlo_pi(int(1e7)) for i in range(10)]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iWuTLHk0aOLj"},"outputs":[],"source":["%%timeit\n","[monte_carlo_pi_cp(int(1e7)) for i in range(10)]"]},{"cell_type":"markdown","metadata":{"id":"S4wsUi5paOLj"},"source":["GPU spedup functions are optimized for at least four things: \n","\n","- Input size \n","- Compute complexity \n","- CPU/GPU copying \n","- Data type. \n","\n","Concretely, a gpu spedup function can be slow because the input size is too small, the computation is too simple, there is excessive data copying to/from GPU/CPU, and the input types matters."]},{"cell_type":"markdown","metadata":{"id":"2_8yVa0caOLj"},"source":["## Laboratories"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b_9MmUjRaOLk"},"outputs":[],"source":["# Baseline\n","def cdist(xs, ys):\n","    \"\"\"Returns pairwise distance between row vectors in xs and ys.\n","    \n","    xs has shape (m, p)\n","    ys has shape (n, p)\n","    \n","    Return value has shape (m, n)    \n","    \"\"\"\n","    \n","    m, p = xs.shape\n","    n, p = ys.shape\n","    \n","    res = np.empty((m, n))\n","    for i in range(m):\n","        for j in range(n):\n","            res[i, j] = np.sqrt(np.sum((ys[j] - xs[i])**2))\n","    return res"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ak-oqZWUaOLk"},"outputs":[],"source":["m = 1000\n","n = 1000\n","p = 100\n","\n","X = np.random.random((m, p))\n","Y = np.random.random((n, p))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZIzY-EXlaOLk"},"outputs":[],"source":["Z = cdist(X, Y)\n","Z"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AwMtKra2aOLk"},"outputs":[],"source":["%%timeit\n","Z = cdist(X, Y)"]},{"cell_type":"markdown","metadata":{"id":"4lryc8hLaOLk"},"source":["### Using `CuPy`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kNVVQ3uBaOLk"},"outputs":[],"source":["# Baseline\n","def cdist_cupy(xs, ys):\n","    \"\"\"Returns pairwise distance between row vectors in xs and ys.\n","    \n","    xs has shape (m, p)\n","    ys has shape (n, p)\n","    \n","    Return value has shape (m, n)    \n","    \"\"\"\n","    \n","    m, p = xs.shape\n","    n, p = ys.shape\n","    \n","    res = cp.empty((m, n))\n","    for i in range(m):\n","        for j in range(n):\n","            #res[i, j] = cp.linalg.norm(ys[j] - xs[i])\n","            res[i, j] = cp.sqrt(cp.sum((ys[j] - xs[i])**2))\n","    return res"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zITECuS-aOLk"},"outputs":[],"source":["m = 1000\n","n = 1000\n","p = 100\n","\n","#X2 = cp.random.random((m, p))\n","#Y2 = cp.random.random((n, p))\n","X2 = cp.asarray(X)\n","Y2 = cp.asarray(Y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F14W-UxtaOLk"},"outputs":[],"source":["%%time\n","Z2 = cdist_cupy(X2, Y2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fAs7EVvXaOLl"},"outputs":[],"source":["np.allclose(Z,Z2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bh-_GzDFaOLl"},"outputs":[],"source":["Z3 = np.empty((1000,1000))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g31lGSqxaOLl"},"outputs":[],"source":["%%timeit\n","for i in range(X.shape[0]):\n","    Z3[i,:] = np.sqrt(((np.broadcast_to(X[i,:], X.shape) - Y)**2).sum(axis=1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8cS_TP96aOLl"},"outputs":[],"source":["%%timeit\n","for i in range(X.shape[0]):\n","    Z3[i,:] = np.linalg.norm((np.broadcast_to(X[i,:], X.shape) - Y), axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CV8UFmpzaOLl"},"outputs":[],"source":["np.allclose(Z,Z3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PHAAOIiYaOLl"},"outputs":[],"source":["Z4 = cp.empty((1000,1000))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WEOHo9-7aOLl"},"outputs":[],"source":["%%timeit\n","for i in range(X2.shape[0]):\n","    Z4[i,:] = cp.sqrt(((cp.broadcast_to(X2[i,:], X2.shape) - Y2)**2).sum(axis=1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uJgcZhtnaOLl"},"outputs":[],"source":["%%timeit\n","for i in range(X2.shape[0]):\n","    Z4[i,:] = cp.linalg.norm((cp.broadcast_to(X2[i,:], X2.shape) - Y2), axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H0pLoJSraOLm"},"outputs":[],"source":["np.allclose(Z,Z4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"31SBWFdVaOLm"},"outputs":[],"source":["import scipy.spatial"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uKIm4pITaOLm"},"outputs":[],"source":["%%timeit\n","scipy.spatial.distance.cdist(X,Y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6-WHik1DaOLm"},"outputs":[],"source":["Z5 = scipy.spatial.distance.cdist(X,Y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ptBjRZinaOLm"},"outputs":[],"source":["np.allclose(Z,Z5)"]},{"cell_type":"markdown","metadata":{"id":"h2Xyh31saOLm"},"source":["## Exercise 4: \n","- Calculate the pairwise euclidean distance between two matrices X and Y using method you learn in this minicourse and report the speedup over baseline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vZ9X7bBDaOLm"},"outputs":[],"source":["## Solution here"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mceRXF28aOLm"},"outputs":[],"source":["from joblib import Parallel, delayed\n","from numba import jit, njit\n","from functools import partial\n","from tqdm import tqdm\n","tqdm = partial(tqdm, position=0, leave=True)"]},{"cell_type":"markdown","metadata":{"id":"PwagGiVxaOLn"},"source":["### Using optimized formula to calculate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LU6ABTDnaOLn"},"outputs":[],"source":["## The formula is from https://www.pythonlikeyoumeanit.com/Module3_IntroducingNumpy/Broadcasting.html#The-Final-Answer,-At-Last!\n","def pairwise_dists(x, y): \n","    \"\"\" Computing pairwise distances using memory-efficient\n","    vectorization.\n","\n","    Parameters\n","    ----------\n","    x : numpy.ndarray, shape=(M, D)\n","    y : numpy.ndarray, shape=(N, D)\n","\n","    Returns\n","    -------\n","    numpy.ndarray, shape=(M, N)\n","        The Euclidean distance between each pair of\n","        rows between `x` and `y`.\"\"\"\n","    sqr_dists = -2 * np.matmul(x, y.T)\n","    sqr_dists +=  np.sum(x**2, axis=1)[:, np.newaxis]\n","    sqr_dists += np.sum(y**2, axis=1)\n","    return  np.sqrt(np.clip(sqr_dists, a_min=0, a_max=None))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eDrsROzRaOLn"},"outputs":[],"source":["Z6 = pairwise_dists(X,Y)\n","np.allclose(Z,Z6)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u0CD0RWBaOLn"},"outputs":[],"source":["%%timeit\n","Z6 = pairwise_dists(X,Y)"]},{"cell_type":"markdown","metadata":{"id":"rE8wyYHtaOLn"},"source":["The speedup is 6.95/0.0167~ 416.2 times faster"]},{"cell_type":"markdown","metadata":{"id":"syLLBDjjaOLn"},"source":["### Numba + joblib"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YfFYLcY3aOLn"},"outputs":[],"source":["@njit\n","def cdist_numba1(xs, ys):\n","    \"\"\"Returns pairwise distance between row vectors in xs and ys.\n","    \n","    xs has shape (m, p)\n","    ys has shape (n, p)\n","    \n","    Return value has shape (m, n)    \n","    \"\"\"\n","    \n","    m, p = xs.shape\n","    n, p = ys.shape\n","    \n","    res = np.empty((m, n))\n","    for i in range(m):\n","        for j in range(n):\n","            s = 0\n","            for k in range(p):\n","                s += (ys[j,k] - xs[i,k])**2\n","            res[i, j] = np.sqrt(s)\n","    return res"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1R8qHO7uaOLn"},"outputs":[],"source":["Z7 = Parallel(n_jobs=8)(delayed(cdist_numba1)(X_, Y) for X_ in tqdm(np.split(X, 10, 0)))\n","Z7 = np.concatenate(Z7)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CoTuGLJ-aOLo"},"outputs":[],"source":["np.allclose(Z,Z7)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3YypFmWraOLo"},"outputs":[],"source":["%%timeit\n","Z7 = Parallel(n_jobs=8)(delayed(cdist_numba1)(X_, Y) for X_ in tqdm(np.split(X, 10, 0)))\n","Z7 = np.concatenate(Z7)"]},{"cell_type":"markdown","metadata":{"id":"WoPGJkiJaOLo"},"source":["The speedup is 6.95/0.0523~ 132.9 times faster"]},{"cell_type":"markdown","metadata":{"id":"Jg3CSrlCaOLo"},"source":["### Cython+joblib"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k8YeFkG-aOLo"},"outputs":[],"source":["%load_ext cython"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Wp60XncaOLo"},"outputs":[],"source":["%%cython\n","\n","import cython\n","import numpy as np\n","from libc.math cimport sqrt, pow\n","from joblib import wrap_non_picklable_objects\n","\n","@wrap_non_picklable_objects\n","@cython.boundscheck(False)\n","@cython.wraparound(False)\n","def cdist_cython(double[:, :] xs, double[:, :] ys):\n","    \"\"\"Returns pairwise distance between row vectors in xs and ys.\n","    \n","    xs has shape (m, p)\n","    ys has shape (n, p)\n","    \n","    Return value has shape (m, n)    \n","    \"\"\"\n","    \n","    cdef int m, n, p\n","    \n","    m = xs.shape[0]\n","    n = ys.shape[0]\n","    p = xs.shape[1]\n","    \n","    cdef double[:, :] res = np.empty((m, n))\n","    \n","    cdef int i, j\n","    \n","    cdef double s\n","    with cython.nogil:\n","        for i in range(m):\n","            for j in range(n):\n","                s = 0.0\n","                for k in range(p):\n","                    s += pow(ys[j,k] - xs[i,k], 2)                \n","                res[i, j] = sqrt(s)\n","    return res"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b4dcmuyEaOLo"},"outputs":[],"source":["from joblib import parallel_backend\n","with parallel_backend(\"threading\"):  \n","    Z8 = Parallel(n_jobs=8)(delayed(cdist_cython)(X_, Y) for X_ in tqdm(np.split(X, 10, 0)))\n","    Z8 = np.concatenate(Z8)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4DaURPAtaOLo"},"outputs":[],"source":["np.allclose(Z,Z8)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KEp18O13aOLp"},"outputs":[],"source":["%%timeit\n","with parallel_backend(\"threading\"):  \n","    Z8 = Parallel(n_jobs=8)(delayed(cdist_cython)(X_, Y) for X_ in tqdm(np.split(X, 10, 0)))\n","    Z8 = np.concatenate(Z8)"]},{"cell_type":"markdown","metadata":{"id":"Hfmm5J_iaOLp"},"source":["The speedup is 6.95/0.035~ 198.6 times faster"]},{"cell_type":"markdown","metadata":{"id":"jk374UMTaOLp"},"source":["### CuPy+joblib"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lEGcKYWiaOLp"},"outputs":[],"source":["def cdist_cupy(X,Y):\n","    return cp.linalg.norm((cp.broadcast_to(X, X.shape) - Y), axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"58CbWaXaaOLp"},"outputs":[],"source":["Z9 = Parallel(n_jobs=8)(delayed(cdist_cupy)(X2[i,:], Y2) for i in tqdm(range(1000)))\n","Z9 = np.vstack(Z9)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mUL3bKmmaOLp"},"outputs":[],"source":["np.allclose(Z,Z9)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rIy37GF1aOLp"},"outputs":[],"source":["%%timeit\n","Z9 = Parallel(n_jobs=8)(delayed(cdist_cupy)(X2[i,:], Y2) for i in tqdm(range(1000)))"]},{"cell_type":"markdown","metadata":{"id":"9B-uRaKHaOLp"},"source":["The speedup is 6.95/0.7~ 9.9 times faster"]},{"cell_type":"markdown","metadata":{"id":"KVK1cZuMaOLq"},"source":["## Referecnes\n","- https://developer.nvidia.com/blog/tag/cuda-refresher/ - A great review for CUDA programming\n","- https://nyu-cds.github.io/python-numba/05-cuda/ - A good introduction for using cuda from `Numba`\n","- https://carpentries-incubator.github.io/gpu-speedups/01_CuPy_and_Numba_on_the_GPU/index.html - A good introduction for `CuPy` and `Numba`\n","- https://www.olcf.ornl.gov/cuda-training-series/ - A great up to date course for CUDA"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"nbdime-conflicts":{"local_diff":[{"diff":[{"diff":[{"key":0,"length":1,"op":"removerange"}],"key":"version","op":"patch"}],"key":"language_info","op":"patch"}],"remote_diff":[{"diff":[{"diff":[{"diff":[{"key":2,"op":"addrange","valuelist":"7"},{"key":2,"length":1,"op":"removerange"}],"key":0,"op":"patch"}],"key":"version","op":"patch"}],"key":"language_info","op":"patch"}]},"colab":{"provenance":[],"collapsed_sections":[]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}
{"cells":[{"cell_type":"markdown","metadata":{"id":"8nDlDihj1RCG"},"source":["# Enhancing performance using Parallel computing\n","- Start by profiling a serial program to identify bottlenecks\n","- Are there opportunities for parallelism?\n","    - Loops\n","    - Can data be split in parallel?\n","    - Pipeline of stages?\n","- Choose an approach and pattern\n","- Map to the parallel environment\n","    - Multicore\n","    - GPU\n","    - Multinode\n","\n","## Embarrassingly parallel programs\n","Many problems are embarrassingly parallel and can be easily decomposed into independent tasks or data sets. Here are several examples:\n","\n","- Monte Carlo integration\n","- Bootstrap for calculating statistics\n","- Fitting the same model on multiple data sets\n","- Running simulation with different settings\n","\n","There are many parallel design patterns. The simplest way is to divide it into \n","\n","- Data parallelism means that the data is distributed across processes (e.g., MPI, Hadoop, Spark)\n","- Task parallelism means that tasks (functions) are distributed across processes, and different units of work (data) are sent to each task (e.g., multithreading, multiprocessing, single GPU programming)."]},{"cell_type":"markdown","metadata":{"id":"s5PNv4531RCI"},"source":["## Using multiple cores with `multiprocessing`\n","\n","The standard implementation of Python uses a Global Interpreter Lock (GIL). This means that only one thread can be run at any one time, and multiple threads work by time-slicing. Hence multi-threaded code with lots of latency (waiting for the network to respond, I/O) can result in speed-ups, but multi-threaded code which is computationally intensive will not see any speed-up. For numerically intensive code, parallel code needs to be run in separate processes to see speed-ups.\n","\n","- Process\n","    - Heavyweight\n","    - Have a separate memory space\n","    - Large cost for communications\n","- Thread\n","    - Lightweight\n","    - Share the same memory space\n","    - Small cost for communications"]},{"cell_type":"markdown","metadata":{"id":"iNSv5aEx1RCJ"},"source":["First we see how to split the computation into pieces using a loop."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pEAluW6V1RCK"},"outputs":[],"source":["from multiprocessing import (Pool, Process, cpu_count)\n","import multiprocessing as mp\n","import time\n","from numba import njit\n","from math import sqrt\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5EVccksb1RCK"},"outputs":[],"source":["cpu_count()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ihrD1H0f1RCL"},"outputs":[],"source":["[sqrt(i ** 2) for i in range(10)]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B9uC59Sw1RCM"},"outputs":[],"source":["%%writefile defs.py\n","from math import sqrt\n","\n","def sqrt_list(i):\n","    return sqrt(i**2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HdpP6VXW1RCN"},"outputs":[],"source":["import defs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zVP1uVBb1RCN"},"outputs":[],"source":["with mp.Pool(processes=cpu_count()) as pool:\n","    res = pool.map(defs.sqrt_list, [i for i in range(10)])\n","res"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SdQg0wfo1RCO"},"outputs":[],"source":["res"]},{"cell_type":"markdown","metadata":{"id":"_dbfMcIH1RCP"},"source":["### Functions with multiple arguments"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yGwy9i3o1RCP"},"outputs":[],"source":["%%writefile defs2.py\n","\n","def f(a, b, c):\n","    return a + b + c"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1ltZpaCj1RCQ"},"outputs":[],"source":["import defs2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9wLdHgwy1RCQ"},"outputs":[],"source":["x = np.arange(24)\n","x_s = np.array_split(x, x.shape[0]//3)\n","x_s"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eeNXQaTy1RCQ"},"outputs":[],"source":["with mp.Pool(processes=cpu_count()) as pool:\n","    res = pool.starmap(defs2.f, x_s)\n","res"]},{"cell_type":"markdown","metadata":{"id":"Jqu6VV7L1RCR"},"source":["#### MoteCarlo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LCV1y4Zh1RCR"},"outputs":[],"source":["%%writefile defs3.py\n","import numpy as np\n","\n","def monte_carlo_pi(n):\n","    x = np.random.uniform(-1, 1, (n,2))\n","    return 4*np.sum((x**2).sum(1) < 1)/n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"12Ms7-8O1RCR"},"outputs":[],"source":["import defs3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d75Q-e8F1RCR"},"outputs":[],"source":["%%timeit  \n","global res\n","res = [defs3.monte_carlo_pi(int(1e7)) for i in range(10)]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0bLORE6h1RCS"},"outputs":[],"source":["%%timeit\n","global re2\n","with mp.Pool(processes=cpu_count()) as pool:\n","    res2 = pool.map(defs3.monte_carlo_pi, [int(1e7) for i in range(10)])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a-RP-m7j2KUI"},"outputs":[],"source":["%%timeit\n","global re2\n","with mp.Pool(processes=40) as pool:\n","    res2 = pool.map(defs3.monte_carlo_pi, [int(1e7) for i in range(10)])"]},{"cell_type":"markdown","metadata":{"id":"EA39o5zV1RCS"},"source":["- Check map_async vs map https://discuss.python.org/t/differences-between-pool-map-pool-apply-and-pool-apply-async/6575/2 "]},{"cell_type":"markdown","metadata":{"id":"PYju_Dtk1RCS"},"source":["## Using `Threading`"]},{"cell_type":"markdown","metadata":{"id":"vi9EISVO1RCS"},"source":["- Check threading vs multiprocessing https://blog.floydhub.com/multiprocessing-vs-threading-in-python-what-every-data-scientist-needs-to-know/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eURtNR8E1RCT"},"outputs":[],"source":["from multiprocessing.dummy import Pool as ThreadPool\n","import requests"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oUvMAuGq1RCT"},"outputs":[],"source":["def func(number):\n","    url = 'http://example.com/'\n","    for i in range(number):\n","        response = requests.get(url)\n","        print(len(response.text))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sYdTWG4h1RCT"},"outputs":[],"source":["with ThreadPool(processes=4) as pool:\n","    res2 = pool.map(func, [3,3,3,3])"]},{"cell_type":"markdown","metadata":{"id":"i93ifCM61RCT"},"source":["## Using `Joblib`"]},{"cell_type":"markdown","metadata":{"id":"npfJk7n81RCT"},"source":["`joblib` provides parallel processing using a comprehension syntax"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tr0WW2Df1RCT"},"outputs":[],"source":["from joblib import Parallel, delayed\n","from functools import partial\n","from tqdm import tqdm\n","tqdm = partial(tqdm, position=0, leave=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SbSw-Kes1RCU"},"outputs":[],"source":["Parallel(n_jobs=4)(delayed(sqrt)(i ** 2) for i in tqdm(range(10)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tInSm2Vw1RCU"},"outputs":[],"source":["x = np.arange(24)\n","x_s = np.array_split(x, x.shape[0]//3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bo70e38p1RCU"},"outputs":[],"source":["res = Parallel(n_jobs=4)(delayed(defs2.f)(x_s[i][0], x_s[i][1], x_s[i][2]) for i in tqdm(range(len(x_s))))\n","res"]},{"cell_type":"markdown","metadata":{"id":"Dy1AZfdQ1RCU"},"source":["Using thread"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_eJu85wv1RCU"},"outputs":[],"source":["res = Parallel(n_jobs=4, prefer=\"threads\")(delayed(defs2.f)(x_s[i][0], x_s[i][1], x_s[i][2]) for i in tqdm(range(len(x_s))))\n","res"]},{"cell_type":"markdown","metadata":{"id":"3JbyccTp1RCU"},"source":["MonteCarlo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ILwZrpOx1RCU"},"outputs":[],"source":["%%timeit\n","res = Parallel(n_jobs=4, prefer=\"threads\")(delayed(defs3.monte_carlo_pi)(int(1e7)) for i in tqdm(range(10)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ze62ar8D28Kq"},"outputs":[],"source":["%%timeit\n","res = Parallel(n_jobs=40, prefer=\"threads\")(delayed(defs3.monte_carlo_pi)(int(1e7)) for i in tqdm(range(10)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PBm6H7311RCV"},"outputs":[],"source":["%%timeit\n","res = Parallel(n_jobs=2)(delayed(defs3.monte_carlo_pi)(int(1e7)) for i in tqdm(range(10)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ST8hfip83H46"},"outputs":[],"source":["%%timeit\n","res = Parallel(n_jobs=40)(delayed(defs3.monte_carlo_pi)(int(1e7)) for i in tqdm(range(10)))"]},{"cell_type":"markdown","metadata":{"id":"rsuiObt31RCV"},"source":["- Scientific Python libraries such as numpy, `scipy`, `pandas` and `scikit-learn` often release the GIL in performance-critical code paths. It is therefore advised to always measure the speed of thread-based parallelism and use it when the GIL does not limit the scalability.\n","- The thread-based approach can also ease debugging\n","\n","- Writing to shared memory requires careful coordination of processes, and many control and communication concepts are implemented in the multiprocessing library for this purpose, including semaphores, locks, barriers, etc. \n","- Check share memory and reduction at https://milliams.com/courses/parallel_python/\n","- Check Numba parallel features"]},{"cell_type":"markdown","metadata":{"id":"B4oNVpfN1RCV"},"source":["## Laboratories"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CYM1KJys1RCV"},"outputs":[],"source":["# Baseline\n","def cdist(xs, ys):\n","    \"\"\"Returns pairwise distance between row vectors in xs and ys.\n","    \n","    xs has shape (m, p)\n","    ys has shape (n, p)\n","    \n","    Return value has shape (m, n)    \n","    \"\"\"\n","    \n","    m, p = xs.shape\n","    n, p = ys.shape\n","    \n","    res = np.empty((m, n))\n","    for i in range(m):\n","        for j in range(n):\n","            res[i, j] = np.sqrt(np.sum((ys[j] - xs[i])**2))\n","    return res"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fPO30Mae1RCV"},"outputs":[],"source":["xs = np.arange(6).reshape(3,2).astype('float')\n","ys = np.arange(4).reshape(2,2).astype('float')\n","zs = cdist(xs, ys)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lVUDwi6Y1RCW"},"outputs":[],"source":["cdist(xs, ys)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Z8g7-x51RCW"},"outputs":[],"source":["np.split(xs, 3, 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8f8jhx8q1RCW"},"outputs":[],"source":["res = np.concatenate([cdist(x, ys) for x in np.split(xs, 3, 0)])\n","res"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9IHcID171RCW"},"outputs":[],"source":["m = 1000\n","n = 1000\n","p = 100\n","\n","X = np.random.random((m, p))\n","Y = np.random.random((n, p))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JPoT5YF_1RCW"},"outputs":[],"source":["%%timeit\n","Z = cdist(X, Y)"]},{"cell_type":"markdown","metadata":{"id":"gBbwlBSR1RCW"},"source":["### Using `multiprocessing`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G0uk4ZQV1RCW"},"outputs":[],"source":["from multiprocessing import Pool"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"56jofAGx1RCW"},"outputs":[],"source":["%%writefile defs4.py\n","import numpy as np\n","\n","def cdist(xs, ys):\n","    \"\"\"Returns pairwise distance between row vectors in xs and ys.\n","    \n","    xs has shape (m, p)\n","    ys has shape (n, p)\n","    \n","    Return value has shape (m, n)    \n","    \"\"\"\n","    \n","    m, p = xs.shape\n","    n, p = ys.shape\n","    \n","    res = np.empty((m, n))\n","    for i in range(m):\n","        for j in range(n):\n","            res[i, j] = np.sqrt(np.sum((ys[j] - xs[i])**2))\n","    return res"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sm2NlEk-1RCX"},"outputs":[],"source":["import defs4"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tCGFaN3Z1RCX"},"outputs":[],"source":["%%timeit\n","with Pool(processes=4) as p:\n","    Z1 = p.starmap(defs4.cdist, [(X_, Y) for X_ in np.split(X, 100, 0)])\n","    Z1 = np.concatenate(Z1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XCnCK3Uk1RCX"},"outputs":[],"source":["Z = cdist(X, Y)\n","\n","with Pool(processes=4) as p:\n","    Z1 = p.starmap(defs4.cdist, [(X_, Y) for X_ in np.split(X, 100, 0)])\n","    Z1 = np.concatenate(Z1)\n","\n","np.allclose(Z, Z1)"]},{"cell_type":"markdown","metadata":{"id":"fx7tX-Po1RCX"},"source":["### Using threads\n","\n","Note that there is no gain with using multiple threads for computationally intensive tasks because of the GIL."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c5yWN2Vd1RCX"},"outputs":[],"source":["%%timeit\n","with ThreadPool(processes=4) as pool:\n","    Z2 = list(pool.starmap(defs4.cdist, [(X_, Y) for X_ in np.split(X, 100, 0)]))\n","    Z2 = np.concatenate(Z2)"]},{"cell_type":"markdown","metadata":{"id":"BR4ONBj_1RCX"},"source":["Check"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AFDByZQG1RCY"},"outputs":[],"source":["with ThreadPool(processes=4) as pool:\n","    Z2 = list(pool.starmap(defs4.cdist, [(X_, Y) for X_ in np.split(X, 100, 0)]))\n","    Z2 = np.concatenate(Z2)\n","\n","np.allclose(Z, Z2)"]},{"cell_type":"markdown","metadata":{"id":"L5QoDCUf1RCY"},"source":["## Exercise 3: \n","- Calculate the pairwise euclidean distance between two matrices X and Y using `joblib` and report the speedup (or speed down) over baseline\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8nEZRxr2YbIf"},"outputs":[],"source":["Z3 = Parallel(n_jobs=4)(delayed(cdist)(X_, Y) for X_ in tqdm(np.split(X, 100, 0)))\n","Z3 = np.concatenate(Z3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UP1GVh3bYbIf"},"outputs":[],"source":["np.allclose(Z, Z3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cZzMovYvn_K3"},"outputs":[],"source":["%%timeit\n","## Solution here\n","Z3 = Parallel(n_jobs=4)(delayed(cdist)(X_, Y) for X_ in tqdm(np.split(X, 100, 0)))\n","Z3 = np.concatenate(Z3)"]},{"cell_type":"markdown","metadata":{"id":"SYv54bZ2YbIf"},"source":["The speedup is 6.84/3.87~ 1.8 times faster"]},{"cell_type":"markdown","metadata":{"id":"lV3fSXe91RCZ"},"source":["## References\n","- https://people.duke.edu/~ccc14/sta-663-2018/notebooks/S14A_Parallel_Programming_Introduction.html - A series of great introduction for HPC\n","- https://blog.floydhub.com/multiprocessing-vs-threading-in-python-what-every-data-scientist-needs-to-know/ - A series of great discussion on multiprocessing and multithreading\n","- https://www.maxlist.xyz/2020/03/15/gil-thread-safe-atomic/ - The concept of thread-safe\n","- https://joblib.readthedocs.io/en/latest/parallel.html - A good guide for using `joblib`"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"nbdime-conflicts":{"local_diff":[{"diff":[{"diff":[{"key":0,"length":1,"op":"removerange"}],"key":"version","op":"patch"}],"key":"language_info","op":"patch"}],"remote_diff":[{"diff":[{"diff":[{"diff":[{"key":2,"op":"addrange","valuelist":"7"},{"key":2,"length":1,"op":"removerange"}],"key":0,"op":"patch"}],"key":"version","op":"patch"}],"key":"language_info","op":"patch"}]}},"nbformat":4,"nbformat_minor":0}